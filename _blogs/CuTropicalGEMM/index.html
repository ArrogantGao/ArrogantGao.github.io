<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel=stylesheet  href="/libs/katex/katex.min.css"> <link rel=stylesheet  href="/libs/highlight/styles/github.min.css"> <link rel=stylesheet  href="/css/franklin.css"> <link rel=stylesheet  href="/css/jemdoc.css"> <link rel=icon  href="/assets/profile.png"> <title>CuTropicalGEMM.jl</title> <main class=outside > <div class=box > <aside class=layout-menu > <div class=menu-category >Xuanzhao Gao's Site</div> <div class="menu-item "><a href="/">Home</a></div> <div class=menu-category >Blogs</div> <div class="menu-item current"><a href="/_blogs/CuTropicalGEMM/">GEMM on GPU</a></div> </aside> <div class=layout-content > <div class=franklin-content > <h1 id=how_to_implement_generic_matrix_multiplication_gemm_with_generic_element_types_on_gpu ><a href="#how_to_implement_generic_matrix_multiplication_gemm_with_generic_element_types_on_gpu" class=header-anchor >How to implement generic matrix multiplication &#40;GEMM&#41; with generic element types on GPU?</a></h1> <p>This blog is a technical note for the <a href="https://summer-ospp.ac.cn/">Open Source Promotion Plan 2023</a> project <a href="https://summer-ospp.ac.cn/org/prodetail/23fec0105?lang&#61;en&amp;list&#61;pro">&quot;TropicalGEMM on GPU&quot;</a> released by JuliaCN, where I developed a <a href="https://julialang.org/">Julia</a> package <a href="github.com/TensorBFS/CuTropicalGEMM.jl">CuTropicalGemm.jl</a> calculate Generic Matrix Multiplication &#40;GEMM&#41; of Tropical Numbers on Nvidia GPUs.</p> <p>This blog covers the following contents:</p> <ol> <li><p>What is Tropical algebra? Why we need that?</p> <li><p>What is <code>Julia</code> programing language and why it is useful?</p> <li><p>Why GPU is fast and how to implement a fast generic matrix multiplication on Nvidia GPU?</p> <li><p>How to join the <a href="https://summer-ospp.ac.cn/">Open Source Promotion Plan</a>?</p> </ol> <h2 id=what_is_tropical_algebra_and_why_we_need_it ><a href="#what_is_tropical_algebra_and_why_we_need_it" class=header-anchor >What is Tropical Algebra and why we need it?</a></h2> <p><a href="https://en.wikipedia.org/wiki/Tropical_geometry">Tropical algebra</a> is a set of <a href="https://en.wikipedia.org/wiki/Semiring">semiring algebra</a>, which is a generalization of a ring, dropping the requirement that each element must have an additive inverse. Generally, they can be defined as a set <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> equipped with two binary operations <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊕</mo></mrow><annotation encoding="application/x-tex">\oplus</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6667em;vertical-align:-0.0833em;"></span><span class=mord >⊕</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊗</mo></mrow><annotation encoding="application/x-tex">\otimes</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6667em;vertical-align:-0.0833em;"></span><span class=mord >⊗</span></span></span></span>, called addition and multiplication, such that:</p> <ul> <li><p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>R</mi><mo separator=true >,</mo><mo>⊕</mo><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(R, \oplus)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >⊕</span><span class=mclose >)</span></span></span></span> is a monoid with identity element called <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn mathvariant=double-struck >0</mn></mrow><annotation encoding="application/x-tex">\mathbb{0}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >0</span></span></span></span>;</p> <li><p><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>R</mi><mo separator=true >,</mo><mo>⊗</mo><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(R, \otimes)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >⊗</span><span class=mclose >)</span></span></span></span> is a monoid with identity element called <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn mathvariant=double-struck >1</mn></mrow><annotation encoding="application/x-tex">\mathbb{1}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >1</span></span></span></span>;</p> <li><p>Addition is commutative;</p> <li><p>Multiplication by the additive identity <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn mathvariant=double-struck >0</mn></mrow><annotation encoding="application/x-tex">\mathbb{0}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >0</span></span></span></span> annihilates ;</p> <li><p>Multiplication left- and right-distributes over addition;</p> <li><p>Explicitly stated, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>R</mi><mo separator=true >,</mo><mo>⊕</mo><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(R, \oplus)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >⊕</span><span class=mclose >)</span></span></span></span> is a commutative monoid.</p> </ul> <p>A Tropical algebra can be described as a tuple <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>R</mi><mo separator=true >,</mo><mo>⊕</mo><mo separator=true >,</mo><mo>⊗</mo><mo separator=true >,</mo><mn mathvariant=double-struck >0</mn><mo separator=true >,</mo><mn mathvariant=double-struck >1</mn><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(R, \oplus, \otimes, \mathbb{0}, \mathbb{1})</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >⊕</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >⊗</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >0</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >1</span><span class=mclose >)</span></span></span></span>, where <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>R</mi></mrow><annotation encoding="application/x-tex">R</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.00773em;">R</span></span></span></span> is the set, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊕</mo></mrow><annotation encoding="application/x-tex">\oplus</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6667em;vertical-align:-0.0833em;"></span><span class=mord >⊕</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>⊗</mo></mrow><annotation encoding="application/x-tex">\otimes</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6667em;vertical-align:-0.0833em;"></span><span class=mord >⊗</span></span></span></span> are the opeartions and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn mathvariant=double-struck >0</mn></mrow><annotation encoding="application/x-tex">\mathbb{0}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >0</span></span></span></span>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn mathvariant=double-struck >1</mn></mrow><annotation encoding="application/x-tex">\mathbb{1}</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >1</span></span></span></span> are their identity element, respectively. Here some commonly used algebras are listed below:</p> <ul> <li><p><code>TropicalAndOr</code>: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mo stretchy=false >[</mo><mi>T</mi><mo separator=true >,</mo><mi>F</mi><mo stretchy=false >]</mo><mo separator=true >,</mo><mo>∨</mo><mo separator=true >,</mo><mo>∧</mo><mo separator=true >,</mo><mi>F</mi><mo separator=true >,</mo><mi>T</mi><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">([T, F], \lor, \land, F, T)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >([</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class=mclose >]</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >∨</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >∧</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">F</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class=mclose >)</span></span></span></span>;</p> <li><p><code>TropicalMaxPlus</code> &#40;also simply called <code>Tropical</code>&#41;: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi mathvariant=double-struck >R</mi><mo separator=true >,</mo><mi>max</mi><mo>⁡</mo><mo separator=true >,</mo><mo>+</mo><mo separator=true >,</mo><mo>−</mo><mi mathvariant=normal >∞</mi><mo separator=true >,</mo><mn>0</mn><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(\mathbb{R}, \max, +, -\infty, 0)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathbb">R</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop >max</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >+</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >−</span><span class=mord >∞</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >0</span><span class=mclose >)</span></span></span></span>;</p> <li><p><code>TropicalMinPlus</code>: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi mathvariant=double-struck >R</mi><mo separator=true >,</mo><mi>min</mi><mo>⁡</mo><mo separator=true >,</mo><mo>+</mo><mo separator=true >,</mo><mi mathvariant=normal >∞</mi><mo separator=true >,</mo><mn>0</mn><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(\mathbb{R}, \min, +, \infty, 0)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathbb">R</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop >min</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >+</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >∞</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >0</span><span class=mclose >)</span></span></span></span>;</p> <li><p><code>TropicalMaxMul</code>: <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><msup><mi mathvariant=double-struck >R</mi><mo>+</mo></msup><mo separator=true >,</mo><mi>max</mi><mo>⁡</mo><mo separator=true >,</mo><mo>×</mo><mo separator=true >,</mo><mn>0</mn><mo separator=true >,</mo><mn>1</mn><mo stretchy=false >)</mo></mrow><annotation encoding="application/x-tex">(\mathbb{R}^+, \max, \times, 0, 1)</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1.0213em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class=mord ><span class="mord mathbb">R</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.7713em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">+</span></span></span></span></span></span></span></span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mop >max</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >×</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >0</span><span class=mpunct >,</span><span class=mspace  style="margin-right:0.1667em;"></span><span class=mord >1</span><span class=mclose >)</span></span></span></span>.</p> </ul> <p>In recent years, the tropical numbers have been widely used in various areas, including optimization, physics, and computer science, due to its computational simplicity.</p> <p>For example, it was shown that solving the groud state energy of spin glass problem can be mapped as contraction of a tropical tensor network, which is actually calculating tons of matrix multiplication of Tropical numbers, as shown in</p> <ul> <li><p><a href="https://arxiv.org/abs/2008.06888">arxiv: Tropical Tensor Network for Ground States of Spin Glasses</a></p> <li><p><a href="https://www.youtube.com/watch?v&#61;l_7xZ4trcnE">Lei Wang: &quot;Tropical Tensor Networks&quot;</a></p> </ul> <p>However, these works are built on top of a poorly implemented tropical matrix multiplication routine that can only use less than <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >10</span></span></span></span> percent of the theoreical computational power of a GPU device &#40;check the benchmark below&#41;. With a proper implement the tropical GEMM on CUDA, these algorithms could be speed up for more than one orders.</p> <p>Recently, it has also been considered to use the Tropical algebra in machine learning area, as shown in </p> <ul> <li><p><a href="https://arxiv.org/abs/2307.03056">Generalizing Backpropagation for Gradient-Based Interpretability</a></p> <li><p><a href="https://arxiv.org/abs/2002.00876">Torch-Struct: Deep Structured Prediction Library</a></p> </ul> <p>For these purposes, a fast implementation of the TropicalGEMM on GPU is on demand.</p> <h2 id=matrix_multiplication_of_tropical_numbers_on_gpu ><a href="#matrix_multiplication_of_tropical_numbers_on_gpu" class=header-anchor >Matrix Multiplication of Tropical Numbers on GPU</a></h2> <p>We achieved fast TropicalGEMM via two packages in <code>Julia</code>.</p> <ul> <li><p><a href="github.com/TensorBFS/TropicalNumbers.jl"><code>TropicalNumbers.jl</code></a>: an interface for Tropical Numbers, which will allow users to use tropical numbers just like normal numbers.</p> <li><p><a href="github.com/TensorBFS/CuTropicalGEMM.jl"><code>CuTropicalGEMM.jl</code></a>: a fast implementation of the TropicalGEMM on GPU, fast and easy to use.</p> </ul> <p>In the following part of this section, we will mainly introduce these two packages. Including how to use them and how we developed them.</p> <h3 id=julia_programing_language ><a href="#julia_programing_language" class=header-anchor >Julia Programing Language</a></h3> <p>As we mentioned above, we choose to use the <code>Julia</code> programing language, which is becoming more and more popular in the past few years. Why we choose <code>Julia</code>? Let&#39;s just copy an introduction from <a href="https://arxiv.org/pdf/1712.03112.pdf">Effective Extensible Programming: Unleashing Julia on GPUs</a>:</p> <blockquote> <p>Julia is a high-level, high-performance dynamic program- ming language for technical computing. It features a type system with parametric polymorphism, multiple dispatch, metaprogramming capabilities, and other high- level features. The most remarkable aspect of the language and its main implementation is speed: carefully written Julia code performs exceptionally well on traditional microprocessors, approaching the speed of code written in statically-compiled languages like C or FORTRAN.</p> <p>Julia’s competitive performance originates from clever language design that avoids the typical compilation and exe- cution uncertainties associated with dynamic languages. For example, Julia features a systemic vocabulary of types, with primitive types &#40;integers, floats&#41; mapping onto machine- native representations. The compiler uses type inference to propagate type information throughout the program, tagging locations &#40;variables, temporaries&#41; with the type known at compile time. If a location is fully typed and the layout of that type is known, the compiler can often use stack memory to store its value. In contrast, uncertainty with respect to the type of a location obligates variably-sized run-time heap allocations, with type tags next to values and dynamic checks on those tags as is common in many high-level languages.</p> </blockquote> <p>Briefly, <code>Julia</code> is fast, and easy to use.</p> <p><img src="/assets/CuTropicalGEMM_figs/Julia_meme.png" alt=Julia_Meme  /></p> <h3 id=user_friendly_tropical_interface_tropicalnumbersjl ><a href="#user_friendly_tropical_interface_tropicalnumbersjl" class=header-anchor >User Friendly Tropical Interface: <code>TropicalNumbers.jl</code></a></h3> <p>For convenience, we want to use tropical number just like normal numbers willout lose of performance, so that we make use of the type system in <code>Julia</code>.</p> <p>Type system of <code>Julia</code> allows us to create our own types, and <code>Julia</code> support multiple dispatch based on that. In Julia, the operators <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo></mrow><annotation encoding="application/x-tex">+</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6667em;vertical-align:-0.0833em;"></span><span class=mord >+</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.4653em;"></span><span class=mord >∗</span></span></span></span> could overloaded elegantly with <a href="https://en.wikipedia.org/wiki/Multiple_dispatch">multiple dispatch</a>, which is a feature not available in object oriented languages such as <code>Python</code> and <code>C&#43;&#43;</code>.</p> <p>Base on that, we simply define the Tropical number as a new number type, and overload the correspond operations. That is what we do in package <a href="github.com/TensorBFS/TropicalNumbers.jl">TropicalNumbers.jl</a>.</p> <pre><code class="julia hljs"><span class=hljs-keyword >abstract type</span> AbstractSemiring &lt;: <span class=hljs-built_in >Number</span> <span class=hljs-keyword >end</span>

<span class=hljs-keyword >struct</span> Tropical{T} &lt;: AbstractSemiring
    n::T

    Tropical{T}(x) <span class=hljs-keyword >where</span> T = new{T}(T(x))
    <span class=hljs-keyword >function</span> Tropical(x::T) <span class=hljs-keyword >where</span> T
        new{T}(x)
    <span class=hljs-keyword >end</span>
<span class=hljs-keyword >end</span>

Base.:*(a::Tropical, b::Tropical) = Tropical(a.n + b.n)
Base.:+(a::Tropical, b::Tropical) = Tropical(max(a.n, b.n))</code></pre> <p>In that case, users can use the tropical algebra just like normal numbers, for example</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-keyword >using</span> TropicalNumbers

julia&gt; a, b = Tropical(<span class=hljs-number >1.0</span>), Tropical(<span class=hljs-number >2.0</span>)
(<span class=hljs-number >1.0</span>ₜ, <span class=hljs-number >2.0</span>ₜ)

julia&gt; a + b, a * b
(<span class=hljs-number >2.0</span>ₜ, <span class=hljs-number >3.0</span>ₜ)</code></pre> <p>and opeartions of vectors and matrices also work</p> <pre><code class="julia hljs">julia&gt; A = Tropical.(rand(<span class=hljs-number >2</span>, <span class=hljs-number >2</span>))
<span class=hljs-number >2</span>×<span class=hljs-number >2</span> <span class=hljs-built_in >Matrix</span>{Tropical{<span class=hljs-built_in >Float64</span>}}:
 <span class=hljs-number >0.2238665251106623</span>ₜ  <span class=hljs-number >0.18355043791779635</span>ₜ
 <span class=hljs-number >0.3673107532619566</span>ₜ   <span class=hljs-number >0.1573950170887196</span>ₜ

julia&gt; B = Tropical.(rand(<span class=hljs-number >2</span>))
<span class=hljs-number >2</span>-element <span class=hljs-built_in >Vector</span>{Tropical{<span class=hljs-built_in >Float64</span>}}:
 <span class=hljs-number >0.16479545470285972</span>ₜ
  <span class=hljs-number >0.3666513822212566</span>ₜ

julia&gt; A * B
<span class=hljs-number >2</span>-element <span class=hljs-built_in >Vector</span>{Tropical{<span class=hljs-built_in >Float64</span>}}:
 <span class=hljs-number >0.5502018201390529</span>ₜ
 <span class=hljs-number >0.5321062079648163</span>ₜ</code></pre> <p>Since we define the tropical number as a subtype of <code>Number</code>,</p> <pre><code class="julia hljs">julia&gt; isbitstype(Tropical{<span class=hljs-built_in >Float64</span>})
<span class=hljs-literal >true</span></code></pre> <p>which means the storage of an array of tropical numbers in the memory is continium, just like normal numbers.</p> <p>We also implemented other Tropical algebra, you can use them like that:</p> <pre><code class="julia hljs">julia&gt; TropicalAndOr(<span class=hljs-literal >true</span>), TropicalMinPlus(<span class=hljs-number >1.0</span>), TropicalMaxMul(<span class=hljs-number >1.0</span>)
(trueₜ, <span class=hljs-number >1.0</span>ₛ, <span class=hljs-number >1.0</span>ₓ)</code></pre> <p>All these things work naturally, users will be able to use the tropical algebra just like real numbers.</p> <h3 id=fast_tropicalgemm_on_gpu_cutropicalgemmjl ><a href="#fast_tropicalgemm_on_gpu_cutropicalgemmjl" class=header-anchor >Fast TropicalGEMM on GPU: <code>CuTropicalGEMM.jl</code></a></h3> <p><code>CuTropicalGEMM.jl</code> is the package we developed to speed up the TropicalGEMM on Nvidia GPU. In this package, we use <code>C-Cuda</code> directly for the lower level interface to achieve a high performace and then wrap the code with a <code>Julia</code> interface, so that it is easy to use.</p> <p>Before further introduction, let me first show you a simple benchmark result on NVIDIA A800 80GB PCIe: <img src="/assets/CuTropicalGEMM_figs/benchmark.png" alt=Benchmark  /> We compared the performance of <code>CuTropicalGEMM.jl</code>, <a href="https://github.com/JuliaGPU/GemmKernels.jl">GemmKernels.jl</a> and direct CUDA.jl map reduce on Tropical GEMM with single precision. The performance is defined as</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mfrac><mrow><mn>2</mn><mo>×</mo><mi>M</mi><mo>×</mo><mi>K</mi><mo>×</mo><mi>N</mi></mrow><mi>T</mi></mfrac><mtext> </mtext><mo separator=true >,</mo></mrow><annotation encoding="application/x-tex"> \frac{2 \times M \times K \times N}{T}\;, </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:2.0463em;vertical-align:-0.686em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3603em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >2</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mpunct >,</span></span></span></span></span> <p>where <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span></span></span></span>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span>, <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> are the size of the matrix so that <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>M</mi><mi>N</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">2MNK</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class=mord >2</span><span class="mord mathnormal" style="margin-right:0.10903em;">MN</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> is the number of total operations in matrix multiplication, and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span></span></span></span> is the time cost. The performance of Cublas on normal GEMM is used as a reference of the maximum computing power. Clearly, the result shows that the performance of our package is about <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>75</mn><mi mathvariant=normal >%</mi></mrow><annotation encoding="application/x-tex">75\%</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.8056em;vertical-align:-0.0556em;"></span><span class=mord >75%</span></span></span></span> of the theortical maximum, which is quite high since the tropical algebra can not use the fused multiple add &#40;FMA&#41; opeartions.</p> <h4 id=how_to_use_this_package ><a href="#how_to_use_this_package" class=header-anchor >How to use this package?</a></h4> <p><code>CuTropicalGEMM.jl</code> can be easily used, just like the <code>TropicalNumbers.jl</code>. We fully used the multiple dispatch in <code>Julia</code> and overloaded the function <code>LinearAlgebra.mul&#33;</code> for the types <code>CuVecOrMat&#123;Tropical&#125;</code>, which will be called when you use <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.4653em;"></span><span class=mord >∗</span></span></span></span> between these tropical vectors or matrices.</p> <p>Here is an example:</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-keyword >using</span> CUDA, LinearAlgebra, TropicalNumbers, CuTropicalGEMM

julia&gt; A = CuArray(Tropical.(rand(<span class=hljs-number >2</span>,<span class=hljs-number >2</span>)))
<span class=hljs-number >2</span>×<span class=hljs-number >2</span> CuArray{Tropical{<span class=hljs-built_in >Float64</span>}, <span class=hljs-number >2</span>, CUDA.Mem.DeviceBuffer}:
 <span class=hljs-number >0.5682481722270427</span>ₜ  <span class=hljs-number >0.7835411877064771</span>ₜ
 <span class=hljs-number >0.4228348375216514</span>ₜ  <span class=hljs-number >0.9492658562534506</span>ₜ

julia&gt; B = CuArray(Tropical.(rand(<span class=hljs-number >2</span>,<span class=hljs-number >2</span>)))
<span class=hljs-number >2</span>×<span class=hljs-number >2</span> CuArray{Tropical{<span class=hljs-built_in >Float64</span>}, <span class=hljs-number >2</span>, CUDA.Mem.DeviceBuffer}:
 <span class=hljs-number >0.37361925746020586</span>ₜ   <span class=hljs-number >0.6628092509923389</span>ₜ
  <span class=hljs-number >0.3415957179381368</span>ₜ  <span class=hljs-number >0.28749655890269377</span>ₜ

julia&gt; A * B
<span class=hljs-number >2</span>×<span class=hljs-number >2</span> CuArray{Tropical{<span class=hljs-built_in >Float64</span>}, <span class=hljs-number >2</span>, CUDA.Mem.DeviceBuffer}:
 <span class=hljs-number >1.1251369056446139</span>ₜ  <span class=hljs-number >1.2310574232193816</span>ₜ
 <span class=hljs-number >1.2908615741915874</span>ₜ  <span class=hljs-number >1.2367624151561443</span>ₜ</code></pre> <p>Or if you want to use a pre-allocate matrix <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span></span></span></span> or calculate <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>+</mo><mi>A</mi><mo>×</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C + A \times B</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal">A</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span></span></span></span>, you can use:</p> <pre><code class="julia hljs">julia&gt; C = CuArray(Tropical.(zeros(<span class=hljs-number >2</span>, <span class=hljs-number >2</span>)));

julia&gt; mul!(C, A, B)
<span class=hljs-number >2</span>×<span class=hljs-number >2</span> CuArray{Tropical{<span class=hljs-built_in >Float64</span>}, <span class=hljs-number >2</span>, CUDA.Mem.DeviceBuffer}:
 <span class=hljs-number >1.1251369056446139</span>ₜ  <span class=hljs-number >1.2310574232193816</span>ₜ
 <span class=hljs-number >1.2908615741915874</span>ₜ  <span class=hljs-number >1.2367624151561443</span>ₜ</code></pre> <p>To benchmark the performance, you can use the <code>@benchmark</code> and <code>CUDA.@sync</code> marco.</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-keyword >using</span> CUDA, CuTropicalGEMM, TropicalNumbers

julia&gt; A = TropicalF32.(CUDA.rand(<span class=hljs-number >4096</span>, <span class=hljs-number >4096</span>));

julia&gt; B = TropicalF32.(CUDA.rand(<span class=hljs-number >4096</span>, <span class=hljs-number >4096</span>));

julia&gt; <span class=hljs-meta >@benchmark</span> CUDA.<span class=hljs-meta >@sync</span> $(A) * $(B)
BenchmarkTools.Trial: <span class=hljs-number >53</span> samples with <span class=hljs-number >5</span> evaluations.
 Range (min … max):   <span class=hljs-number >6.691</span> μs …    <span class=hljs-number >1.574</span> s  ┊ GC (min … max): <span class=hljs-number >0.00</span>% … <span class=hljs-number >0.00</span>%
 Time  (median):      <span class=hljs-number >7.117</span> μs               ┊ GC (median):    <span class=hljs-number >0.00</span>%
 Time  (mean ± σ):   <span class=hljs-number >29.701</span> ms ± <span class=hljs-number >216.171</span> ms  ┊ GC (mean ± σ):  <span class=hljs-number >0.00</span>% ± <span class=hljs-number >0.00</span>%

  █▅
  ██▅▃▃▄▃▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▃ ▁
  <span class=hljs-number >6.69</span> μs         Histogram: frequency by time         <span class=hljs-number >30.7</span> μs &lt;

 Memory estimate: <span class=hljs-number >256</span> bytes, allocs estimate: <span class=hljs-number >7.</span></code></pre> <p>and what is important here is the <code>mean</code> time &#40;currently there are some issues about the detection of time cost and we are still working on that&#41;.</p> <p>You can also use that in more complicated cases, when developing you own package, by <code>using CuTropicalGEMM</code>, the <code>mul&#33;</code> opeartions between Tropical matrices will be overloaded. Here is an example to directly use this package to speed up the maximum independent set &#40;MIS&#41; problem.</p> <pre><code class="julia hljs">julia&gt; <span class=hljs-keyword >using</span> GenericTensorNetworks, GenericTensorNetworks.Graphs, CUDA, Random

julia&gt; g = Graphs.random_regular_graph(<span class=hljs-number >200</span>, <span class=hljs-number >3</span>)
{<span class=hljs-number >200</span>, <span class=hljs-number >300</span>} undirected simple <span class=hljs-built_in >Int64</span> graph

julia&gt; item(x::<span class=hljs-built_in >AbstractArray</span>) = <span class=hljs-built_in >Array</span>(x)[];

julia&gt; optimizer = TreeSA(ntrials=<span class=hljs-number >1</span>);

julia&gt; gp = IndependentSet(g; optimizer=optimizer);

julia&gt; contraction_complexity(gp)
Time complexity: <span class=hljs-number >2</span>^<span class=hljs-number >30.519117443024154</span>
Space complexity: <span class=hljs-number >2</span>^<span class=hljs-number >24.0</span>
Read-write complexity: <span class=hljs-number >2</span>^<span class=hljs-number >27.24293120300714</span>

julia&gt; <span class=hljs-meta >@time</span> CUDA.<span class=hljs-meta >@sync</span> solve(gp, SizeMax(); usecuda=<span class=hljs-literal >true</span>, T=<span class=hljs-built_in >Float32</span>)
 <span class=hljs-number >31.104404</span> seconds (<span class=hljs-number >48.07</span> M allocations: <span class=hljs-number >3.239</span> GiB, <span class=hljs-number >2.31</span>% gc time, <span class=hljs-number >88.25</span>% compilation time: &lt;<span class=hljs-number >1</span>% of which was recompilation)
<span class=hljs-number >0</span>-dimensional CuArray{Tropical{<span class=hljs-built_in >Float32</span>}, <span class=hljs-number >0</span>, CUDA.Mem.DeviceBuffer}:
<span class=hljs-number >89.0</span>ₜ

julia&gt; <span class=hljs-keyword >using</span> CuTropicalGEMM

julia&gt; <span class=hljs-meta >@time</span> CUDA.<span class=hljs-meta >@sync</span> solve(gp, SizeMax(); usecuda=<span class=hljs-literal >true</span>, T=<span class=hljs-built_in >Float32</span>)
  <span class=hljs-number >0.361831</span> seconds (<span class=hljs-number >440.99</span> k allocations: <span class=hljs-number >28.131</span> MiB, <span class=hljs-number >85.79</span>% compilation time: <span class=hljs-number >100</span>% of which was recompilation)
<span class=hljs-number >0</span>-dimensional CuArray{Tropical{<span class=hljs-built_in >Float32</span>}, <span class=hljs-number >0</span>, CUDA.Mem.DeviceBuffer}:
<span class=hljs-number >89.0</span>ₜ</code></pre> <h4 id=why_it_is_fast ><a href="#why_it_is_fast" class=header-anchor >Why it is fast?</a></h4> <p>Here we will breifly introduce the techniques we used to speed up our code, which are commonly used in GPU implementation of GEMM. We learned a lot from the repo <a href="https://github.com/Cjkkkk/CUDA_gemm">CUDA_gemm</a> by <a href="https://cjkkkk.github.io">Cjkkk</a>. Here we will briefly introduce these techinques, and for more detailed introduction, I recommand this <a href="https://zhuanlan.zhihu.com/p/441146275">blog</a> in Chinese.</p> <p>As we all know, Nvidia GPU is fast because it have a large amount of cuda cores. For example, the Nvidia A800 GPU have <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6912</mn></mrow><annotation encoding="application/x-tex">6912</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >6912</span></span></span></span> cuda cores, which is much more larger than the number of CPU cores, which is normally less than <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >100</span></span></span></span>. The peak flops of A800 is about <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>19.5</mn></mrow><annotation encoding="application/x-tex">19.5</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >19.5</span></span></span></span>T, which is also much higher than that of CPU, for example <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >0.5</span></span></span></span>T for an Intel i7-10700K.</p> <p><img src="https://www.intel.com/content/dam/developer/articles/technical/comparing-cpus-gpus-and-fpgas-for-oneapi/CvGvF_CPU_GPU.jpg" alt="CPU vs GPU" /></p> <p>However, each cuda core is much weaker than that of CPU, so that the developer will have to properly allocate the tasks to these cores so that can fully use them. In a CUDA kernel, each cuda core is used by a <em>thread</em> and these <em>threads</em> are grouped as <em>blocks</em>.</p> <p>Another imortant aspect is the memory of GPU, there are three type of programable memories on GPU:</p> <ul> <li><p>Global memory, shared by all blocks, large but slow.</p> <li><p>Shared memory, shared by threads in the same block, small but fast, just like a programable L1 cache.</p> <li><p>Registers, used by only one thread.</p> </ul> <p>Driectly loading data from global memory will take a long time, the bandwidth is only about <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1000</mn></mrow><annotation encoding="application/x-tex">1000</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >1000</span></span></span></span>GB/s and the latency is about <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>600</mn></mrow><annotation encoding="application/x-tex">600</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >600</span></span></span></span> cycles on A800 GPU. For shared memory, its bandwidth is about <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20000</mn></mrow><annotation encoding="application/x-tex">20000</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >20000</span></span></span></span>GB/s while the latency is only about <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>23</mn></mrow><annotation encoding="application/x-tex">23</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >23</span></span></span></span> cycles, so that another main target in GPU programing is to properly use the memory, avoid directly loading from the global memory and pre-load the needed data into the shared memory. </p> <p>GEMM is a very memory-intensive operation, for example, when calculating the GEMM between a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">M \times K</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> matrix and a <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mo>×</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">K \times N</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> matrix, if we use the naive way, i.e. evaluating the element in the result matrix one by one, for each element we will have to load <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mi>K</mi></mrow><annotation encoding="application/x-tex">2K</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class=mord >2</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> data, and there are <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>M</mi><mo>×</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">M \times N</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> elements in total. Then we will have to load <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mi>M</mi><mo>×</mo><mi>K</mi><mo>×</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">2 \times M \times K \times N</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7278em;vertical-align:-0.0833em;"></span><span class=mord >2</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span></span></span></span> elements from the slow global memeory directly to registers in the whole process, and this generally far exceeds the data bandwidth of the GPU, resulting in serious performance issues.</p> <p>To avoid the heavy data loading, we first split the target matrix blocks with size <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">BM \times BN</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span></span></span></span>, and each GPU block will be used to calculate one of the matrix blocks, as shown in the fig below: </p> <p><img src="/assets/CuTropicalGEMM_figs/block.png" alt=Fig.1  /></p> <p>When calculating each block, we only need to load matrices with size <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>M</mi><mo>×</mo><mi>B</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">BM \times BK</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> and <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mi>K</mi><mo>×</mo><mi>B</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">BK \times BN</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span></span></span></span> for <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi><mi mathvariant=normal >/</mi><mi>B</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">K / BK</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mord >/</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> times from global memory to shared memory. In that case, the total data loading will be reduce to </p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>M</mi><mo>×</mo><mi>N</mi><mo>×</mo><mi>K</mi><mo>×</mo><mrow><mo fence=true >(</mo><mfrac><mn>1</mn><mrow><mi>B</mi><mi>M</mi></mrow></mfrac><mo>+</mo><mfrac><mn>1</mn><mrow><mi>B</mi><mi>N</mi></mrow></mfrac><mo fence=true >)</mo></mrow></mrow><annotation encoding="application/x-tex"> M \times N \times K \times \left( \frac{1}{BM} + \frac{1}{BN} \right) </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:2.4em;vertical-align:-0.95em;"></span><span class=minner ><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3214em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mord ><span class="mopen nulldelimiter"></span><span class=mfrac ><span class="vlist-t vlist-t2"><span class=vlist-r ><span class=vlist  style="height:1.3214em;"><span style="top:-2.314em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span></span></span><span style="top:-3.23em;"><span class=pstrut  style="height:3em;"></span><span class=frac-line  style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class=pstrut  style="height:3em;"></span><span class=mord ><span class=mord >1</span></span></span></span><span class=vlist-s >​</span></span><span class=vlist-r ><span class=vlist  style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span></span></span></span></span> <p>which is much smaller than the naive way.</p> <p>Then in each block, we further divide the matrix and use the registers to store the data, as shown by</p> <p><img src="/assets/CuTropicalGEMM_figs/thread.png" alt=Fig.1  /></p> <p>The target matrix will be further divided as small matrices with size <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mi>M</mi><mo>×</mo><mi>T</mi><mi>N</mi></mrow><annotation encoding="application/x-tex">TM \times TN</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7667em;vertical-align:-0.0833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span></span></span></span>, and each thread will be used to calculate one of the matrix. During this process, the outer product way is used and data will be loaded from shared memory to registers, with the amount of <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy=false >(</mo><mi>T</mi><mi>M</mi><mo>+</mo><mi>T</mi><mi>N</mi><mo stretchy=false >)</mo><mo>×</mo><mi>B</mi><mi>K</mi></mrow><annotation encoding="application/x-tex">(TM + TN) \times BK</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class=mopen >(</span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >+</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span><span class=mclose >)</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span></span></span></span> in total. In our package, we set the parameters as</p> <span class=katex-display ><span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML" display=block ><semantics><mrow><mi>B</mi><mi>M</mi><mo>=</mo><mn>64</mn><mo separator=true >,</mo><mtext> </mtext><mi>B</mi><mi>K</mi><mo>=</mo><mn>32</mn><mo separator=true >,</mo><mtext> </mtext><mi>B</mi><mi>N</mi><mo>=</mo><mn>64</mn><mo separator=true >,</mo><mtext> </mtext><mi>T</mi><mi>M</mi><mo>=</mo><mi>T</mi><mi>N</mi><mo>=</mo><mn>4.</mn></mrow><annotation encoding="application/x-tex"> BM = 64,~BK = 32,~BN = 64,~TM = TN = 4. </annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BM</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.8778em;vertical-align:-0.1944em;"></span><span class=mord >64</span><span class=mpunct >,</span><span class="mspace nobreak"> </span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.07153em;">K</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.8778em;vertical-align:-0.1944em;"></span><span class=mord >32</span><span class=mpunct >,</span><span class="mspace nobreak"> </span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">BN</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.8778em;vertical-align:-0.1944em;"></span><span class=mord >64</span><span class=mpunct >,</span><span class="mspace nobreak"> </span><span class=mspace  style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TM</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.10903em;">TN</span><span class=mspace  style="margin-right:0.2778em;"></span><span class=mrel >=</span><span class=mspace  style="margin-right:0.2778em;"></span></span><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >4.</span></span></span></span></span> <p>As we mentioned above, the <code>Tropical</code> type is <code>bitstype</code>, and the data storaged in memeories are simply the floating point numbers, which can be directly used by CUDA kernels. Of course here we used the tropical algebra instead of the normal ones. Although the tropical algebra can not use the fused multiple add core &#40;FMA&#41;, we found that the operation add/mul and max/min can be done on FMA and ALU parallelly, which means that we can use the FMA to do the add/mul and ALU to do the max/min at the same time. Then after all the calculation is done, the target in the registers will be stored back to global memory directly.</p> <p>For the boundary elements, a padding strategy is used, we simply set the element which are not acctually in the matrix as the zero element of the corresponding algebra, so that they will not effect the result of the calculation.</p> <h4 id=benchmark ><a href="#benchmark" class=header-anchor >Benchmark</a></h4> <p>Further benchmarking is still in development, and will be uoloaded to this repo <a href="https://github.com/ArrogantGao/CuTropicalGEMM_benchmark">CuTropicalGEMM_benchmark</a>.</p> <h3 id=optimization_of_narrow_matrix_performance ><a href="#optimization_of_narrow_matrix_performance" class=header-anchor >Optimization of Narrow Matrix Performance</a></h3> <p>The second aspect is to further optimize the code, especially the performance on narrow matrices. As mentioned above, our package now is using the padding strategy to handle the boundary elements, and the minimum matrix size we process in each block on the GPU are <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>64</mn><mo>×</mo><mn>32</mn><mo>×</mo><mn>64</mn></mrow><annotation encoding="application/x-tex">64 \times 32 \times 64</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7278em;vertical-align:-0.0833em;"></span><span class=mord >64</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.7278em;vertical-align:-0.0833em;"></span><span class=mord >32</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >64</span></span></span></span>, which is optimal for large square matrices. However, the performance of the code on narrow matrices is not good enough, and the reason is that the padding strategy will enlarge the matrix size a lot. For example, when handling a matrix multiplication with size <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>4</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mn>6</mn></msup></mrow><annotation encoding="application/x-tex">4 \times 4 \times 10^6</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7278em;vertical-align:-0.0833em;"></span><span class=mord >4</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.7278em;vertical-align:-0.0833em;"></span><span class=mord >4</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.8141em;"></span><span class=mord >1</span><span class=mord ><span class=mord >0</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span></span></span></span></span></span></span></span>, what is actually calculated is <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>64</mn><mo>×</mo><mn>32</mn><mo>×</mo><mn>1</mn><msup><mn>0</mn><mn>6</mn></msup></mrow><annotation encoding="application/x-tex">64 \times 32 \times 10^6</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.7278em;vertical-align:-0.0833em;"></span><span class=mord >64</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.7278em;vertical-align:-0.0833em;"></span><span class=mord >32</span><span class=mspace  style="margin-right:0.2222em;"></span><span class=mbin >×</span><span class=mspace  style="margin-right:0.2222em;"></span></span><span class=base ><span class=strut  style="height:0.8141em;"></span><span class=mord >1</span><span class=mord ><span class=mord >0</span><span class=msupsub ><span class=vlist-t ><span class=vlist-r ><span class=vlist  style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class=pstrut  style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">6</span></span></span></span></span></span></span></span></span></span></span>, which means that the code will waste a lot of time on the padding elements. Unfortunately, such narrow matrices are very common in the tensor network contraction process, and the performance of the code on narrow matrices is very important.</p> <p>Now we are considering further optimize the code for narrow matrices, related code are stored in the branch <a href="https://github.com/TensorBFS/CuTropicalGEMM.jl/tree/narrow_matrices">narrow matrices</a>.</p> <h2 id=open_source_promotion_plan ><a href="#open_source_promotion_plan" class=header-anchor >Open Source Promotion Plan</a></h2> <p>As mentioned above, this program is support by <a href="https://summer-ospp.ac.cn/">Open Source Promotion Plan 2023</a>, JuliaCN.</p> <blockquote> <p>Open Source Promotion Plan is a summer program organized by the Institute of Software Chinese Academy of Sciences and long-term supported by the Open Source Software Supply Chain Promotion Plan. It aims to encourage college students to actively participate in the maintenance and development of open source software, promote the vigorous development of open source software communities, and build the open source software supply chain together.</p> </blockquote> <p>I will recommend anyone who is interested in developing open source software to join this plan. During the plan, the open source communities will release <a href="https://summer-ospp.ac.cn/org/orglist">projects</a> and each participant can choose three projects to apply. Once the application is approved, the participants can follow the mentor to complete the program in about three months.</p> <p><img src="/assets/CuTropicalGEMM_figs/timeline.png" alt=timeline  /></p> <p>I think it is a great chance to learn and to build connection with the community.</p> <p>The plan starts in each summer, and the application commonly opens in June. If interested, just go and join OSPP <span class=katex ><span class=katex-mathml ><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2024</mn></mrow><annotation encoding="application/x-tex">2024</annotation></semantics></math></span><span class=katex-html  aria-hidden=true ><span class=base ><span class=strut  style="height:0.6444em;"></span><span class=mord >2024</span></span></span></span>&#33;</p> <h2 id=acknowledgement ><a href="#acknowledgement" class=header-anchor >Acknowledgement</a></h2> <p>I am very grateful for the guidance and assistance provided by Prof. <a href="https://github.com/GiggleLiu">Jinguo Liu</a> during the project implementation process. I would like to thank <a href="https://github.com/maleadt">Tim Besard</a> for his invaluable guidance and support during the development of the package, his expertise in GPU utilization have been immensely helpful. I also want to thank <a href="https://github.com/tylerjthomas9">Tyler Thomas</a> for his assistance in understanding the usage of BinaryBuilder.jl.</p> <div class=page-foot > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Xuanzhao Gao. Last modified: October 22, 2023. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> <script src="/libs/highlight/highlight.min.js"></script> <script>hljs.highlightAll();hljs.configure({tabReplace: ' '});</script> </div> </main>